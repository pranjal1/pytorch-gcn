{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:rgba(192,192,192,0.3); font-size:105%; color:black\">\n",
    "<h3>Reference:</h3>\n",
    "    <a href=\"https://towardsdatascience.com/hands-on-graph-neural-networks-with-pytorch-pytorch-geometric-359487e221a8\">https://towardsdatascience.com/hands-on-graph-neural-networks-with-pytorch-pytorch-geometric-359487e221a8</a>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:rgba(192,192,192,0.3); font-size:105%; color:black\">\n",
    "<h3>Dataset</h3>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:rgba(192,192,192,0.3); font-size:105%; color:black\">\n",
    "<h4> YooChoose Dataset:</h4>\n",
    "<a href = \"https://2015.recsyschallenge.com/challenge.html\">https://2015.recsyschallenge.com/challenge.html</a><br>\n",
    "Given a sequence of click events performed by some user during a typical session in an e-commerce website, the goal is to predict whether the user is going to buy something or not, and if he is buying, what would be the items he is going to buy. The task could therefore be divided into two sub goals:\n",
    "<ol>\n",
    "<li>Is the user going to buy items in this session? Yes|No\n",
    "<li>If yes, what are the items that are going to be bought?\n",
    "</ol>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:rgba(192,192,192,0.3); font-size:105%; color:black\">\n",
    "<b>In this tutorial, we will only be covering Task 1!</b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:rgba(192,192,192,0.3); padding:10px 0; font-size:110%; color:black;\">\n",
    "Pytorch Geometric provides a <b>Dataset</b> interface class that can be inherited to construct the dataset object.<br>\n",
    "The following <b>Dataset</b> interface class methods must to be implemented:\n",
    "<ul>\n",
    "    <li><b>raw_file_names</b></li>\n",
    "    The name of the files to find in the :obj:`self.raw_dir` folder in\n",
    "        order to skip the download.\n",
    "    <li><b>processed_file_names</b></li>\n",
    "    The name of the files to find in the :obj:`self.processed_dir`\n",
    "        folder in order to skip the processing.\n",
    "    <li><b>download</b></li>\n",
    "    Downloads the dataset to the :obj:`self.raw_dir` folder.\n",
    "    <li><b>process</b></li>\n",
    "    Processes the dataset to the :obj:`self.processed_dir` folder.\n",
    "</ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric import utils, data\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from loguru import logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_dir = os.path.join(os.getcwd(), \"tmp\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:rgba(192,192,192,0.3); font-size:105%; color:black\">\n",
    "<h3>Preprocessing</h3>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:rgba(192,192,192,0.3); font-size:105%; color:black\">\n",
    "<b>Load data</b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pranjal/miniconda3/envs/gcn/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3145: DtypeWarning: Columns (3) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    }
   ],
   "source": [
    "session_df = pd.read_csv(os.path.join(target_dir,\"dataset/yoochoose-clicks.dat\"))\n",
    "session_df.columns = [\"session_id\", \"timestamp\", \"item_id\", \"category\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>session_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>item_id</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2014-04-07T10:54:09.868Z</td>\n",
       "      <td>214536500</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2014-04-07T10:54:46.998Z</td>\n",
       "      <td>214536506</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2014-04-07T10:57:00.306Z</td>\n",
       "      <td>214577561</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>2014-04-07T13:56:37.614Z</td>\n",
       "      <td>214662742</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>2014-04-07T13:57:19.373Z</td>\n",
       "      <td>214662742</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   session_id                 timestamp    item_id category\n",
       "0           1  2014-04-07T10:54:09.868Z  214536500        0\n",
       "1           1  2014-04-07T10:54:46.998Z  214536506        0\n",
       "2           1  2014-04-07T10:57:00.306Z  214577561        0\n",
       "3           2  2014-04-07T13:56:37.614Z  214662742        0\n",
       "4           2  2014-04-07T13:57:19.373Z  214662742        0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_id</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>session_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[214536500, 214536506, 214577561]</td>\n",
       "      <td>[0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[214662742, 214662742, 214825110, 214757390, 2...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[214716935, 214774687, 214832672]</td>\n",
       "      <td>[0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[214836765, 214706482]</td>\n",
       "      <td>[0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[214701242, 214826623]</td>\n",
       "      <td>[0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[214826835, 214826715]</td>\n",
       "      <td>[0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[214838855, 214838855]</td>\n",
       "      <td>[0, 0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      item_id  \\\n",
       "session_id                                                      \n",
       "1                           [214536500, 214536506, 214577561]   \n",
       "2           [214662742, 214662742, 214825110, 214757390, 2...   \n",
       "3                           [214716935, 214774687, 214832672]   \n",
       "4                                      [214836765, 214706482]   \n",
       "6                                      [214701242, 214826623]   \n",
       "7                                      [214826835, 214826715]   \n",
       "8                                      [214838855, 214838855]   \n",
       "\n",
       "                      category  \n",
       "session_id                      \n",
       "1                    [0, 0, 0]  \n",
       "2           [0, 0, 0, 0, 0, 0]  \n",
       "3                    [0, 0, 0]  \n",
       "4                       [0, 0]  \n",
       "6                       [0, 0]  \n",
       "7                       [0, 0]  \n",
       "8                       [0, 0]  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#items interacted with during sessions\n",
    "tmp_session_df = session_df[:20].copy()\n",
    "tmp_session_df.groupby(\"session_id\").agg({\"item_id\":list,\"category\":list})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:rgba(192,192,192,0.3); font-size:105%; color:black\">\n",
    "<b>Remove sessions with less than 2 items</b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "session_df[\"valid_session\"] = session_df.session_id.map(\n",
    "        session_df.groupby(\"session_id\")[\"item_id\"].size() > 2\n",
    "    )\n",
    "session_df = session_df.loc[session_df.valid_session].drop(\"valid_session\", axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:rgba(192,192,192,0.3); font-size:105%; color:black\">\n",
    "<b>Sample sessions for demo</b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-09-21 15:26:24.806 | INFO     | __main__:<module>:3 - Sampling 25000 sessions...\n"
     ]
    }
   ],
   "source": [
    "sample_sessions = 25000\n",
    "if sample_sessions:\n",
    "    logger.info(f\"Sampling {sample_sessions} sessions...\")\n",
    "    sampled_session_id = np.random.choice(\n",
    "        session_df.session_id.unique(), sample_sessions, replace=False\n",
    "    )\n",
    "    session_df = session_df.loc[session_df.session_id.isin(sampled_session_id)].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(138910, 4)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:rgba(192,192,192,0.3); font-size:105%; color:black\">\n",
    "<b>Map Item Ids</b><br>\n",
    "<b>item_ids</b> are categorically encoded to ensure the encoded item_ids, which will later be mapped to an embedding matrix, starts at 0.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-09-21 16:58:05.420 | INFO     | __main__:<module>:2 - Mapping item ids to smaller range...\n"
     ]
    }
   ],
   "source": [
    "# map the item ids to a small range\n",
    "logger.info(\"Mapping item ids to smaller range...\")\n",
    "item_encoder = LabelEncoder()\n",
    "session_df[\"item_id\"] = item_encoder.fit_transform(session_df.item_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:rgba(192,192,192,0.3); font-size:105%; color:black\">\n",
    "<b>Determine whether the sessions have buy event</b><br>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "buy_df_path = os.path.join(target_dir,\"dataset/yoochoose-buys.dat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-09-21 16:59:16.570 | INFO     | __main__:<module>:2 - Determining the target class of the sessions (buy/not buy)...\n",
      "2020-09-21 16:59:18.447 | INFO     | __main__:<module>:8 - Loading dataset done!\n"
     ]
    }
   ],
   "source": [
    "# get the target class (buy or not buy event) for the sessions\n",
    "logger.info(\"Determining the target class of the sessions (buy/not buy)...\")\n",
    "buy_df = pd.read_csv(buy_df_path, header=None)\n",
    "buy_df.columns = [\"session_id\", \"timestamp\", \"item_id\", \"price\", \"quantity\"]\n",
    "session_df[\"label\"] = session_df.session_id.isin(buy_df.session_id)\n",
    "num_embeddings = session_df.item_id.max() + 1\n",
    "del buy_df\n",
    "logger.info(\"Loading dataset done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_id</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>False</th>\n",
       "      <td>121035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <td>17875</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       item_id\n",
       "label         \n",
       "False   121035\n",
       "True     17875"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session_df.groupby(\"label\").agg({\"item_id\":len})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:rgba(192,192,192,0.3); font-size:105%; color:black\">\n",
    "<b>Make Graphs</b><br>\n",
    "    The data is ready to be transformed into a Dataset object after the preprocessing step. Here, we treat each item in a session as a node, and therefore all items in the same session form a graph. To build the dataset, we group the preprocessed data by session_id and iterate over these groups. In each iteration, the item_id in each group are categorically encoded again since for each graph, the node index should count from 0.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.data import InMemoryDataset, Data\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-09-21 17:21:16.533 | INFO     | __main__:<module>:4 - Processing dataset...\n",
      "100%|██████████| 25000/25000 [02:10<00:00, 192.22it/s]\n",
      "2020-09-21 17:23:27.072 | INFO     | __main__:<module>:29 - Completed processing!\n",
      "2020-09-21 17:23:27.620 | INFO     | __main__:<module>:32 - Processed files saved as /home/pranjal/GCN/pytorch-gcn/tmp/yoochoose_click_binary_1M_sess_nb.dataset\n"
     ]
    }
   ],
   "source": [
    "data_list = []\n",
    "processed_path = os.path.join(target_dir, \"yoochoose_click_binary_1M_sess_nb.dataset\")\n",
    "\n",
    "logger.info(\"Processing dataset...\")\n",
    "grouped = session_df.groupby(\"session_id\")\n",
    "for session_id, group in tqdm(grouped):\n",
    "    #encode the item_ids for forming the edge_index\n",
    "    sess_item_id = LabelEncoder().fit_transform(group.item_id)\n",
    "    group = group.reset_index(drop=True)\n",
    "    group[\"sess_item_id\"] = sess_item_id\n",
    "    node_features = (\n",
    "        group.loc[group.session_id == session_id, [\"sess_item_id\", \"item_id\"]]\n",
    "        .sort_values(\"sess_item_id\")\n",
    "        .item_id.drop_duplicates()\n",
    "        .values\n",
    "    )\n",
    "\n",
    "    node_features = torch.LongTensor(node_features).unsqueeze(1)\n",
    "    target_nodes = group.sess_item_id.values[1:]\n",
    "    source_nodes = group.sess_item_id.values[:-1]\n",
    "\n",
    "    edge_index = torch.tensor([source_nodes, target_nodes], dtype=torch.long)\n",
    "    x = node_features\n",
    "    # the session id is same for all rows in a session (whether buy event or not)\n",
    "    y = torch.FloatTensor([group.label.values[0]])\n",
    "\n",
    "    data = Data(x=x, edge_index=edge_index, y=y)\n",
    "    data_list.append(data)\n",
    "logger.info(\"Completed processing!\")\n",
    "data, slices = InMemoryDataset.collate(data_list)\n",
    "torch.save((data, slices, num_embeddings), processed_path)\n",
    "logger.info(f\"Processed files saved as {processed_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "del data\n",
    "del slices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "del session_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:rgba(192,192,192,0.3); font-size:105%; color:black\">\n",
    "<h3>All the above steps have been implemented in the following custom DataLoader class</h3>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gcn.dataloader import YooChooseDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-09-21 18:13:51.501 | INFO     | gcn.dataloader:raw_file_names:32 - Required files check!\n"
     ]
    }
   ],
   "source": [
    "ds = YooChooseDataset(root=target_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:rgba(192,192,192,0.3); font-size:105%; color:black\">\n",
    "<h3>Sample Graphs</h3>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "session_num = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_sample = utils.to_networkx(ds[session_num])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nx.draw_kamada_kawai(g_sample,with_labels=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[20112],\n",
       "        [20140]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds[session_num].x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 1, 1, 0],\n",
       "        [1, 1, 0, 0]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds[session_num].edge_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:rgba(192,192,192,0.3); font-size:105%; color:black\">\n",
    "<h3>Model</h3>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:rgba(192,192,192,0.3); font-size:105%; color:black\">\n",
    " <p>The following custom GNN takes reference from one of the examples in <a href=\"https://github.com/rusty1s/pytorch_geometric/blob/master/examples/proteins_topk_pool.py\">PyG’s official Github repository</a>. The <a href=\"https://towardsdatascience.com/hands-on-graph-neural-networks-with-pytorch-pytorch-geometric-359487e221a8\"> author </a> has modified the output layer to match with a binary classification setup.</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import TopKPooling\n",
    "from torch_geometric.nn import global_mean_pool as gap, global_max_pool as gmp\n",
    "\n",
    "from .sage_conv import SAGEConv\n",
    "\n",
    "\n",
    "class Net(torch.nn.Module):\n",
    "    def __init__(self, item_id_max, embed_dim):\n",
    "        super(Net, self).__init__()\n",
    "        self.embed_dim = embed_dim\n",
    "        self.item_id_max = item_id_max\n",
    "        self.conv1 = SAGEConv(self.embed_dim, 128)\n",
    "        self.pool1 = TopKPooling(128, ratio=0.8)\n",
    "        self.conv2 = SAGEConv(128, 128)\n",
    "        self.pool2 = TopKPooling(128, ratio=0.8)\n",
    "        self.conv3 = SAGEConv(128, 128)\n",
    "        self.pool3 = TopKPooling(128, ratio=0.8)\n",
    "        self.item_embedding = torch.nn.Embedding(\n",
    "            num_embeddings=self.item_id_max + 1, embedding_dim=self.embed_dim\n",
    "        )\n",
    "        self.lin1 = torch.nn.Linear(256, 128)\n",
    "        self.lin2 = torch.nn.Linear(128, 64)\n",
    "        self.lin3 = torch.nn.Linear(64, 1)\n",
    "        self.bn1 = torch.nn.BatchNorm1d(128)\n",
    "        self.bn2 = torch.nn.BatchNorm1d(64)\n",
    "        self.act1 = torch.nn.ReLU()\n",
    "        self.act2 = torch.nn.ReLU()\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index, batch = data.x, data.edge_index, data.batch\n",
    "        x = self.item_embedding(x)\n",
    "        x = x.squeeze(1)\n",
    "\n",
    "        x = F.relu(self.conv1(x, edge_index))\n",
    "\n",
    "        x, edge_index, _, batch, _ = self.pool1(x, edge_index, None, batch)\n",
    "        x1 = torch.cat([gmp(x, batch), gap(x, batch)], dim=1)\n",
    "\n",
    "        x = F.relu(self.conv2(x, edge_index))\n",
    "\n",
    "        x, edge_index, _, batch, _ = self.pool2(x, edge_index, None, batch)\n",
    "        x2 = torch.cat([gmp(x, batch), gap(x, batch)], dim=1)\n",
    "\n",
    "        x = F.relu(self.conv3(x, edge_index))\n",
    "\n",
    "        x, edge_index, _, batch, _ = self.pool3(x, edge_index, None, batch)\n",
    "        x3 = torch.cat([gmp(x, batch), gap(x, batch)], dim=1)\n",
    "\n",
    "        x = x1 + x2 + x3\n",
    "\n",
    "        x = self.lin1(x)\n",
    "        x = self.act1(x)\n",
    "        x = self.lin2(x)\n",
    "        x = self.act2(x)\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "\n",
    "        x = torch.sigmoid(self.lin3(x)).squeeze(1)\n",
    "\n",
    "        return x\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train:\n",
    "# copy the code from main.py to here and complete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dl = data.DataLoader(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# item_embedding = torch.nn.Embedding(num_embeddings=ds.num_embeddings, embedding_dim=128)\n",
    "# conv1 = SAGEConv(ds.num_embeddings, 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for tr in dl:\n",
    "#     x, edge_index, batch = tr.x, tr.edge_index, tr.batch\n",
    "#     x = item_embedding(x)\n",
    "#     x = x.squeeze(1)\n",
    "#     y = conv1(x, edge_index)\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = Path(\"ram/shyam/gopal/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PosixPath('/home/pranjal/GCN/pytorch-gcn/ram/shyam'),\n",
       " PosixPath('/home/pranjal/GCN/pytorch-gcn/ram'),\n",
       " PosixPath('/home/pranjal/GCN/pytorch-gcn'),\n",
       " PosixPath('/home/pranjal/GCN'),\n",
       " PosixPath('/home/pranjal'),\n",
       " PosixPath('/home'),\n",
       " PosixPath('/')]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(p.resolve().parents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('gcn': conda)",
   "language": "python",
   "name": "python38564bitgcncondacb855bff8b454c0bbae31f8183fac245"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
