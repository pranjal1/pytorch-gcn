{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><h1>Graph Convolution Network using PyTorch Geometric</h1></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#an image to show what the cell below is describing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:rgba(192,192,192,0.3); padding:10px 0; font-size:110%; color:black;\">\n",
    "<h3>Graphs</h3>\n",
    "<ul>\n",
    "<li>Graphs are a kind of data structure which models a set of objects (nodes) and their relationships (edges).</li>\n",
    "<li>Graphs have great expressive power. It can be used as denotation of a large number of systems across various\n",
    "areas like:</li> \n",
    "    <ul><li>Social science (social networks)</li>\n",
    "        <li>Natural science (physical systems, and protein-protein interaction networks)\n",
    "        <li>Knowledge graphs </li></ul>\n",
    "<li>Low-dimensional vector embeddings of nodes in large graphs have applications in machine learning (e.g., node classification, clustering, link prediction).</li>\n",
    "</ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:rgba(192,192,192,0.3); padding:10px 0; font-size:110%; color:black;\">\n",
    "<h3>Motivation behind Graph Neural Networks</h3>\n",
    "<ul>\n",
    "<li>GNNs are invariant for the input order of nodes.</li>\n",
    "    <ul><li>Standard networks like CNNs and RNNs stack the feature of nodes by a specific order.  However, there\n",
    "isn’t a natural order of nodes in the graph.</li>\n",
    "        <li>To present a\n",
    "graph completely, we should traverse all the possible orders\n",
    "as the input of the model like CNNs and RNNs, which is\n",
    "very redundant when computing.</li></ul>\n",
    "<li>GNNs can do propagation guided by\n",
    "the graph structure.</li> \n",
    "    <ul><li> In the standard neural networks, the\n",
    "dependency information is just regarded as the feature of\n",
    "nodes.</li></ul>\n",
    "</ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:rgba(192,192,192,0.3); padding:10px 0; font-size:110%; color:black;\">\n",
    "<h3>Common Graph Terminologies:</h3>\n",
    "<b>Degree Matrix</b><br>\n",
    "    Given a graph $G=(V,E)$ with $|V|=n$, the degree matrix $D$ for $G$ is a $n\\times n$ diagonal matrix defined as:\n",
    "    $$\\large \\begin{equation}\n",
    "  D_{i,j} :=\n",
    "    \\begin{cases}\n",
    "      \\text{deg}\\left(v_i\\right) & \\text{if $i = j$}\\\\\n",
    "      0 & \\text{otherwise}\n",
    "    \\end{cases}       \n",
    "\\end{equation}$$\n",
    "<center><img src=\"tmp/viz_objects/deg_matrix.png\" alt=\"Input\" width=\"500\"/></center>\n",
    "<b>Adjacency Matrix</b><br>\n",
    "    $$\\large \\begin{equation}\n",
    "  A_{i,j} =\n",
    "    \\begin{cases}\n",
    "      1 & \\text{if $v_i$ and $v_j$ share an edge}\\\\\n",
    "      0 & \\text{if $v_i$ and $v_j$ donot share any edge}\n",
    "    \\end{cases}       \n",
    "\\end{equation}$$\n",
    "<center><img src=\"tmp/viz_objects/adj_matrix.png\" alt=\"Input\" width=\"700\"/></center>\n",
    "<b>Laplacian Matrix</b><br>\n",
    " Given a simple graph $G$ with $n$ vertices, its Laplacian matrix $L_{n\\times n}$ is defined as:\n",
    "    $$\\large L = D - A$$\n",
    " $$\\large \\begin{equation}\n",
    "  L_{i,j} :=\n",
    "    \\begin{cases}\n",
    "      \\text{deg}\\left(v_i\\right) & \\text{if $i = j$}\\\\\n",
    "      -1 & \\text{if $i \\neq j$ and $v_i$ is adjacent $v_j$}\\\\\n",
    "      0 & \\text{otherwise}\n",
    "    \\end{cases}       \n",
    "\\end{equation}$$\n",
    "<center><img src=\"tmp/viz_objects/laplacian_matrix.png\" alt=\"Input\" width=\"1000\"/></center>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:rgba(192,192,192,0.3); padding:10px 0; font-size:110%; color:black;\">\n",
    "<b>Transductive Learning Setting</b>\n",
    "    <ul>\n",
    "    <li>Under transductive learning settings, unlabeled data are\n",
    "accessible for training. This enables the network to learn\n",
    "about the graph structure.</li> \n",
    "     <li>To be specific, only part of nodes\n",
    "are labeled while labels of other nodes in the same graph\n",
    "remain unknown.</li> </ul>\n",
    "<b>Inductive Learning Setting</b>\n",
    "    <ul>\n",
    "    <li>Under inductive learning settings, testing data are not available during training.</li>\n",
    "    <li>The training process\n",
    "does not use graph structures of testing data.</li> </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3><a href=\"https://arxiv.org/abs/1609.02907\">The graph convolutional operator from the \"Semi-supervised Classification with Graph Convolutional Networks\" (ICLR-2017)</a><h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:rgba(192,192,192,0.3); padding:10px 0; font-size:110%; color:black;\">\n",
    "The Kipf and Welling paper describes the Graph Convolution operation as:\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\large H^{(l+1)} = \\sigma\\left(\\tilde{D}^{-\\frac{1}{2}}\\tilde{A}\\tilde{D}^{-\\frac{1}{2}}H^{(l)}W^{(l)}\\right)$$\n",
    "\n",
    "$\\tilde{A} = A+I_{N}\\text{ is the adjacency matrix of the undirected graph G with added self-connections.}$<br>\n",
    "$I_{N}\\text{ is the identity matrix.}$<br>\n",
    "$\\tilde{D}_{ii}=\\Sigma_{j}\\tilde{A}_{ij}\\text{ is the degree matrix.}$<br>\n",
    "$W^{(l)}\\text{ is a layer-specific trainable weight matrix.}$<br>\n",
    "$\\sigma\\text{ denotes the activation function}$<br>\n",
    "$H^{(l)}\\in\\mathbb{R}^{N\\times D}\\text{ is the matrix of activations in the $l^{th}$ layer; $H^{(0)}=X$}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:rgba(192,192,192,0.3); padding:10px 0; font-size:110%; color:black;\">\n",
    "The <a href=\"https://pytorch-geometric.readthedocs.io/en/latest/notes/create_gnn.html\">PyTorch Geometric's implementation</a> for the same is as follows:\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\large \\mathbf{x}_i^{(k)} = \\sum_{j \\in \\mathcal{N}(i) \\cup \\{ i \\}} \\frac{1}{\\sqrt{\\deg(i)} \\cdot \\sqrt{\\deg(j)}} \\cdot \\left( \\mathbf{\\Theta} \\cdot \\mathbf{x}_j^{(k-1)} \\right)$$<br>$\\mathbf{\\Theta}\\text{ is the weight matrix by which the neighboring nodes are transformed.}$<br>$\\mathcal{N}(i)\\text{ are the Neighborhood nodes of node }\\mathcal{i}.$<br>$\\mathbf{x}_j^{(k-1)}\\text{ is the feature of node }\\mathcal{j}\\text{ at layer }\\mathcal{(k-1)}.$<br>$\\mathbf{deg(i)}\\text{ gives the degree of node }\\mathcal{i}\\text{.}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:rgba(192,192,192,0.3); padding:10px 0; font-size:110%; color:black\">\n",
    "The operation can be broken down into the following steps:\n",
    "<ol>\n",
    "    <li> Add self-loops to the Adjacency matrix.\n",
    "    <li> Compute normalization coefficients.\n",
    "    <li> Linearly transform node feature matrix.\n",
    "    <li> Normalize node features in ϕ.\n",
    "    <li> Sum up neighboring node features (if \"add\" aggregation).\n",
    "</ol>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>A Graph network</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch_geometric.data import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define property of the nodes or node features\n",
    "x = torch.tensor([[2,1], [5,6], [3,7], [12,0]], dtype=torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define edges between the nodes\n",
    "edge_index = torch.tensor([[0, 1, 2, 0, 3],\n",
    "                           [1, 0, 1, 3, 2]], dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define the property of edges\n",
    "edge_attr = torch.tensor([4,10,3,1,5],dtype=torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define the classes the nodes belong to\n",
    "y = torch.tensor([0, 1, 0, 1], dtype=torch.float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:rgba(192,192,192,0.3); padding:1px 0; font-size:105%; color:black\">\n",
    "<p>With these defined, the PyTorch Geometric's <b>Data</b> object now can be initialized</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = Data(x=x,edge_index=edge_index,edge_attr=edge_attr,y=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\"tmp/viz_objects/1.png\" alt=\"Input\" width=\"500\" /></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:rgba(192,192,192,0.3); font-size:105%; color:black\">\n",
    "<h4> Step 1:</h4>\n",
    "<p>Add self-loops to the Adjacency matrix.</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:rgba(192,192,192,0.3); font-size:105%; color:black\">\n",
    "<p>This step is required to aggregate the node's own feature with the features of its neighboring nodes:</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:rgba(192,192,192,0.3); font-size:105%; color:black\">\n",
    "<p>Before:</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 1, 2, 0, 3],\n",
       "        [1, 0, 1, 3, 2]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g.edge_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 4., 10.,  3.,  1.,  5.])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g.edge_attr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:rgba(192,192,192,0.3); font-size:105%; color:black\">\n",
    "<p>After:</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.utils import add_remaining_self_loops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_edge_index, new_edge_attr = add_remaining_self_loops(\n",
    "            edge_index, edge_attr, fill_value=1., num_nodes=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 1, 2, 0, 3, 0, 1, 2, 3],\n",
       "        [1, 0, 1, 3, 2, 0, 1, 2, 3]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_edge_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 4., 10.,  3.,  1.,  5.,  1.,  1.,  1.,  1.])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_edge_attr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\"tmp/viz_objects/2.png\" alt=\"Add-Self-Loop\" width=\"700\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:rgba(192,192,192,0.3); font-size:105%; color:black\">\n",
    "<h4> Step 2:</h4>\n",
    "<p>Compute normalization coefficients.</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_scatter import scatter_add"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compute the degree of each node (Sum of weights in edges incoming towards a node)\n",
    "row, col = new_edge_index[0], new_edge_index[1]\n",
    "deg = scatter_add(new_edge_attr, col, dim=0, dim_size=4)#dim_size = num_nodes\n",
    "#Compute the normalization coefficients\n",
    "deg_inv_sqrt = deg.pow_(-0.5)\n",
    "deg_inv_sqrt.masked_fill_(deg_inv_sqrt == float('inf'), 0)\n",
    "normalized_coefficients = deg_inv_sqrt[row] * new_edge_attr * deg_inv_sqrt[col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.4264, 1.0660, 0.4330, 0.2132, 1.4434, 0.0909, 0.1250, 0.1667, 0.5000])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalized_coefficients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:rgba(192,192,192,0.3); font-size:105%; color:black\">\n",
    "<p>Normalizing:</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\"tmp/viz_objects/3.png\" alt=\"Normalize\" width=\"700\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:rgba(192,192,192,0.3); font-size:105%; color:black\">\n",
    "<p>After normalizing:</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\"tmp/viz_objects/3_simplify.png\" alt=\"Simplify\" width=\"700\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:rgba(192,192,192,0.3); font-size:105%; color:black\">\n",
    "<h4> Step 3:</h4>\n",
    "<p>Linearly transform node feature matrix.</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import Parameter\n",
    "from torch_geometric.nn.inits import glorot, zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_channels = 2\n",
    "out_channels = 2 # for vizualization purpose, we are setting it to 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "weight = Parameter(torch.Tensor(in_channels, out_channels))\n",
    "bias = Parameter(torch.Tensor(out_channels))\n",
    "glorot(weight)\n",
    "zeros(bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.matmul(g.x, weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.5858,  3.1582],\n",
       "        [ 2.9603, 11.8331],\n",
       "        [ 0.8006, 10.9251],\n",
       "        [11.2364, 12.1986]], grad_fn=<MmBackward>)"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\"tmp/viz_objects/4_new.png\" alt=\"Convolve\" width=\"700\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:rgba(192,192,192,0.3); font-size:105%; color:black\">\n",
    "<h4> Step 4:</h4>\n",
    "<p>Normalize node features in ϕ.</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:rgba(192,192,192,0.3); font-size:105%; color:black\">\n",
    "<p>Preparing the linearly transformed node features.</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = x.index_select(-2, new_edge_index[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.5858,  3.1582],\n",
       "        [ 2.9603, 11.8331],\n",
       "        [ 0.8006, 10.9251],\n",
       "        [ 1.5858,  3.1582],\n",
       "        [11.2364, 12.1986],\n",
       "        [ 1.5858,  3.1582],\n",
       "        [ 2.9603, 11.8331],\n",
       "        [ 0.8006, 10.9251],\n",
       "        [11.2364, 12.1986]], grad_fn=<IndexSelectBackward>)"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:rgba(192,192,192,0.3); font-size:105%; color:black\">\n",
    "<p>Preparing the normalization coefficients.</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_coefficients = normalized_coefficients.view(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4264],\n",
       "        [1.0660],\n",
       "        [0.4330],\n",
       "        [0.2132],\n",
       "        [1.4434],\n",
       "        [0.0909],\n",
       "        [0.1250],\n",
       "        [0.1667],\n",
       "        [0.5000]])"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalized_coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_node_features = normalized_coefficients * x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.6762,  1.3466],\n",
       "        [ 3.1557, 12.6142],\n",
       "        [ 0.3467,  4.7307],\n",
       "        [ 0.3381,  0.6733],\n",
       "        [16.2183, 17.6071],\n",
       "        [ 0.1442,  0.2871],\n",
       "        [ 0.3700,  1.4791],\n",
       "        [ 0.1334,  1.8208],\n",
       "        [ 5.6182,  6.0993]], grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalized_node_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\begin{pmatrix}\n",
    "     1.5858 &  3.1582 \\\\\n",
    "     2.9603 & 11.8331 \\\\\n",
    "     0.8006 & 10.9251 \\\\\n",
    "     1.5858 &  3.1582 \\\\\n",
    "    11.2364 & 12.1986 \\\\\n",
    "     1.5858 &  3.1582 \\\\\n",
    "     2.9603 & 11.8331 \\\\\n",
    "     0.8006 & 10.9251 \\\\\n",
    "    11.2364 & 12.1986 \\\\\n",
    "    \\end{pmatrix}\n",
    "    \\bullet\n",
    " \\begin{pmatrix}\n",
    " 0.4264\\\\\n",
    " 1.0660\\\\\n",
    " 0.4330\\\\\n",
    " 0.2132\\\\\n",
    " 1.4434\\\\\n",
    " 0.0909\\\\\n",
    " 0.1250\\\\\n",
    " 0.1667\\\\\n",
    " 0.5000\\\\\n",
    "\\end{pmatrix}\n",
    "=\n",
    "\\begin{pmatrix}\n",
    "0.6762 &  1.3466\\\\\n",
    "3.1557 & 12.6142\\\\\n",
    "0.3467 &  4.7307\\\\\n",
    "0.3381 &  0.6733\\\\\n",
    "16.2183 & 17.6071\\\\\n",
    "0.1442 &  0.2871\\\\\n",
    "0.3700 &  1.4791\\\\\n",
    "0.1334 &  1.8208\\\\\n",
    "5.6182 &  6.0993\\\\\n",
    "\\end{pmatrix}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:rgba(192,192,192,0.3); font-size:105%; color:black\">\n",
    "<h4> Step 5:</h4>\n",
    "<p>Sum up neighboring node features (if <b>\"add\"</b> aggregation).</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:rgba(192,192,192,0.3); font-size:105%; color:black\">\n",
    "<p>Other techniques can also be used for aggregation:\n",
    "<ul>\n",
    "<li> Summation\n",
    "<li> Average\n",
    "<li> Max\n",
    "</ul>\n",
    "</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_scatter import scatter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 1, 2, 0, 3, 0, 1, 2, 3],\n",
       "        [1, 0, 1, 3, 2, 0, 1, 2, 3]])"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_edge_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_x = scatter(normalized_node_features, index=new_edge_index[1], dim=-2, dim_size=4,\n",
    "                           reduce=\"add\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 3.2998, 12.9013],\n",
       "        [ 1.3929,  7.5565],\n",
       "        [16.3517, 19.4280],\n",
       "        [ 5.9563,  6.7726]], grad_fn=<ScatterAddBackward>)"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\"tmp/viz_objects/5.png\" alt=\"Updated\" style=\"width: 700px;\"/></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3><a href=\"https://arxiv.org/pdf/1706.02216.pdf\">The GraphSAGE operator from the \"Inductive Representation Learning on Large Graphs\" (NIPS-2017)</a><h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\"tmp/viz_objects/gsage2.png\" alt=\"Updated\" style=\"width: 700px;\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:rgba(192,192,192,0.3); font-size:105%; color:black\">\n",
    "<h4>Motivation:</h4>\n",
    "<ul><li>Most embedding frameworks (during the publication of this paper) are inherently <b>transductive</b> and can only generate embeddings for a single fixed graph. These transductive approaches do not efficiently generalize to unseen nodes (e.g., in evolving graphs), and these approaches cannot learn to generalize across different graphs.\n",
    "    <li>In contrast, GraphSAGE is an <b>inductive</b> framework that leverages node attribute information to efficiently generate representations on previously unseen data. To run GraphSAGE, it needs to train on an example graph or set of graphs. After training, GraphSAGE can be used to generate node embeddings for previously unseen nodes or entirely new input graphs, as long as these graphs have the same attribute schema as the training data.\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:rgba(192,192,192,0.3); font-size:105%; color:black\">\n",
    "The original <a href = \"https://arxiv.org/abs/1609.02907\">GCN algorithm</a> (discussed above) is designed for semi-supervised learning in a <b>transductive</b> setting, and the exact algorithm requires additional information that the full graph Laplacian is known during\n",
    "training.<br>\n",
    "    $$L=D-A$$\n",
    " <ul>\n",
    "    <li>$\\text{L is the graph Laplacian}$\n",
    "    <li>$\\text{D is the Degree matrix}$\n",
    "    <li>$\\text{A is the Adjacency matrix}$\n",
    "  </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:rgba(192,192,192,0.3); font-size:105%; color:black\">\n",
    "<h4> Algorithm</h4>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\"tmp/viz_objects/gsage1.png\" alt=\"Updated\" style=\"width: 700px;\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:rgba(192,192,192,0.3); font-size:105%; color:black\">\n",
    "<h4> Aggregator Functions:</h4>\n",
    "<p>Ideally, an aggregator function would be <b>symmetric</b> (i.e., invariant to permutations of its inputs) while still being <b>trainable and maintaining high representational capacity</b>.\n",
    "The symmetry property of the aggregation function ensures that our neural network model can be trained and applied to arbitrarily ordered node neighborhood feature set.</p>\n",
    "    <ul>\n",
    "        <li> <b>Mean</b> $$\\mathbf{h}_{v}^{k}\\leftarrow\\sigma\\left(\\mathbf{W}\\cdot\\textrm{MEAN}\\left(\\{\\mathbf{h}_{v}^{k-1}\\}\\cup\\{\\mathbf{h}_{u}^{k-1},\\forall u\\in\\mathcal{N}(v)\\}\\right)\\right)$$\n",
    "        <li> <b>Pooling</b> $$\\textrm{AGGREGATE}_{k}^{\\textrm{pool}}\\leftarrow\\max\\left(\\{\\sigma\\left(\\mathbf{W}_{\\textrm{pool}}\\mathbf{h}_{u_i}^{k}+\\mathbf{b}\\right),\\forall u_i\\in\\mathcal{N}(v)\\}\\right)$$\n",
    "        <li> <b>LSTM</b>$$\\textrm{AGGREGATE}_{k}^{\\textrm{LSTM}}\\leftarrow\\textrm{LSTM}\\left([\\textbf{h}_{u}^{k-1},\\forall u\\in\\pi\\left(\\mathcal{N}(v)\\right)]\\right)$$ $$\\pi\\text{ indicates some random permuations of neighbors}$$\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:rgba(192,192,192,0.3); font-size:105%; color:black\">\n",
    "<h4>Incorporating weights in edges:</h4>\n",
    "<ul><li>Trivial method like weighted mean aggregation<li>Using Attention network</ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:rgba(192,192,192,0.3); font-size:105%; color:black\">\n",
    "<h5>Attention mechanism:</h5>\n",
    "    <ul>\n",
    "    <li>Let $\\large a$ compute <b>attention coefficients</b> $\\large e_{vu}$ across pair of nodes $\\large u,v$ based on their messages:</li>\n",
    "        $$\\large e_{vu}=a\\left(\\mathbf{W}_k\\mathbf{h}_{u}^{k-1},\\mathbf{W}_k\\mathbf{h}_{v}^{k-1}\\right)$$\n",
    "            $\\large e_{vu}$ indicates the importance of node $\\large u's$ message to node $\\large v$\n",
    "    <li>Normalize coefficients using the softmax function in order to be comparable across different neighborhoods:</li>\n",
    "        $$\\large \\alpha_{vu}=\\frac{\\text{exp}(e_{vu})}{\\Sigma_{k \\in N(v)}\\text{exp}(e_{vk})}$$\n",
    "    <li>Compute activation using:</li>\n",
    "        $$\\large h_{v}^{k}=\\sigma\\left(\\Sigma_{u \\in N(v)}\\alpha_{vu}\\mathbf{W}_{k}\\mathbf{h}_{u}^{k-1}\\right)$$\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:rgba(192,192,192,0.3); font-size:105%; color:black\">\n",
    "<h4> Loss Function</h4>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:rgba(192,192,192,0.3); font-size:105%; color:black\">\n",
    "In order to learn useful, predictive representations in a fully unsupervised setting, we apply a\n",
    "graph-based loss function to the output representations, $z_u, \\forall u \\in \\mathcal{V}$, and tune the weight matrices,\n",
    "$\\mathbf{W}_k, \\forall k \\in \\{1, ..., K\\},$ and parameters of the aggregator functions via stochastic gradient descent. The\n",
    "graph-based loss function encourages nearby nodes to have similar representations, while enforcing\n",
    "that the representations of disparate nodes are highly distinct:\n",
    "$$\\large J_{\\mathcal{G}}\\left(\\mathbf{z}_{u}\\right)=-\\text{log}\\left(\\sigma\\left(\\mathbf{z}_{u}^{\\text{T}}\\mathbf{z}_{v}\\right)\\right) - Q\\cdot\\mathbb{E}_{v_{n}\\sim P_n(v)}\\text{log}\\left(\\sigma\\left(-\\mathbf{z}_{u}^{\\text{T}}\\mathbf{z}_{v_{n}}\\right)\\right)$$\n",
    "where $v$ is a node that co-occurs near $u$ on fixed-length random walk, $\\sigma$ is the sigmoid function,\n",
    "$P_n$ is a negative sampling distribution, and $Q$ defines the number of negative samples. Importantly,\n",
    "unlike previous embedding approaches, the representations $\\textbf{z}_u$ that we feed into this loss function\n",
    "are generated from the features contained within a node’s local neighborhood, rather than training a\n",
    "unique embedding for each node (via an embedding look-up).\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>A Graph network</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch_geometric.data import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define property of the nodes or node features\n",
    "x = torch.tensor([[2,1], [5,6], [3,7], [12,0]], dtype=torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define edges between the nodes\n",
    "edge_index = torch.tensor([[0, 1, 2, 0, 3],\n",
    "                           [1, 0, 1, 3, 2]], dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define the classes the nodes belong to\n",
    "y = torch.tensor([0, 1, 0, 1], dtype=torch.float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:rgba(192,192,192,0.3); padding:1px 0; font-size:105%; color:black\">\n",
    "<p>Intializing the PyTorch Geometric's <b>Data</b> object</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = Data(x=x,edge_index=edge_index,y=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(edge_index=[2, 5], x=[4, 2], y=[4])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\"tmp/viz_objects/gsage_graph1.png\" alt=\"Simple Graph Network\" style=\"width: 500px;\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:rgba(192,192,192,0.3); font-size:105%; color:black\">\n",
    "<h4> Step 1:</h4>\n",
    "<p>Add self-loops to the Adjacency matrix.</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.utils import add_remaining_self_loops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_edge_index, _ = add_remaining_self_loops(\n",
    "            edge_index, fill_value=1., num_nodes=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 1, 2, 0, 3, 0, 1, 2, 3],\n",
       "        [1, 0, 1, 3, 2, 0, 1, 2, 3]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_edge_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\"tmp/viz_objects/gsage_graph2.png\" alt=\"Add Self Loops\" style=\"width: 500px;\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:rgba(192,192,192,0.3); font-size:105%; color:black\">\n",
    "<h4> Step 2:</h4>\n",
    "<p>Linearly transform node feature matrix.</p>\n",
    "</div> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:rgba(192,192,192,0.3); font-size:105%; color:black\">\n",
    "<p>Preparing the node features.</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = g.x.index_select(-2, new_edge_index[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 2.,  1.],\n",
       "        [ 5.,  6.],\n",
       "        [ 3.,  7.],\n",
       "        [ 2.,  1.],\n",
       "        [12.,  0.],\n",
       "        [ 2.,  1.],\n",
       "        [ 5.,  6.],\n",
       "        [ 3.,  7.],\n",
       "        [12.,  0.]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_channels = 2\n",
    "out_channels = 2 # for vizualization purpose, we are setting it to 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "lin = torch.nn.Linear(in_channels, out_channels)\n",
    "act = torch.nn.ReLU()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_j = lin(x)\n",
    "x_j = act(x_j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 0.5406,  0.5869],\n",
       "        [-0.1657,  0.6496]], requires_grad=True)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lin.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.5132, 0.4609],\n",
       "        [6.0695, 3.2117],\n",
       "        [5.5752, 4.1926],\n",
       "        [1.5132, 0.4609],\n",
       "        [6.3324, 0.0000],\n",
       "        [1.5132, 0.4609],\n",
       "        [6.0695, 3.2117],\n",
       "        [5.5752, 4.1926],\n",
       "        [6.3324, 0.0000]], grad_fn=<ReluBackward0>)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_j"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\"tmp/viz_objects/gsage_graph3.png\" alt=\"Linear Transform nodes\" style=\"width: 500px;\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:rgba(192,192,192,0.3); font-size:105%; color:black\">\n",
    "<h4> Step 3:</h4>\n",
    "<p>Aggregate neighboring node features.</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:rgba(192,192,192,0.3); font-size:105%; color:black\">\n",
    "<p>Techniques for aggregation:\n",
    "<ul>\n",
    "<li> Summation\n",
    "<li> Average\n",
    "<li> Max\n",
    "</ul>\n",
    "</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:rgba(192,192,192,0.3); font-size:105%; color:black\">\n",
    "<p>Using <b>Max</b> aggregation.</p>\n",
    " $$\\textrm{AGGREGATE}_{k}^{\\textrm{pool}}\\leftarrow\\max\\left(\\{\\sigma\\left(\\mathbf{W}_{\\textrm{pool}}\\mathbf{h}_{u_i}^{k}+\\mathbf{b}\\right),\\forall u_i\\in\\mathcal{N}(v)\\}\\right)$$\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_scatter import scatter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 1, 2, 0, 3, 0, 1, 2, 3],\n",
       "        [1, 0, 1, 3, 2, 0, 1, 2, 3]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_edge_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_x = scatter(x_j, index=new_edge_index[1], dim=-2, dim_size=4,\n",
    "                           reduce=\"max\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.51319528, 0.46093252, 1.        ],\n",
       "       [6.06954718, 3.21174693, 0.        ],\n",
       "       [5.57523108, 4.19261456, 1.        ],\n",
       "       [1.51319528, 0.46093252, 3.        ],\n",
       "       [6.33239508, 0.        , 2.        ],\n",
       "       [1.51319528, 0.46093252, 0.        ],\n",
       "       [6.06954718, 3.21174693, 1.        ],\n",
       "       [5.57523108, 4.19261456, 2.        ],\n",
       "       [6.33239508, 0.        , 3.        ]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.concatenate([x_j.detach().numpy(),new_edge_index[1].numpy().reshape(-1,1)],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[6.0695, 3.2117],\n",
       "        [6.0695, 4.1926],\n",
       "        [6.3324, 4.1926],\n",
       "        [6.3324, 0.4609]], grad_fn=<CppNode<ScatterMax>>)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\"tmp/viz_objects/gsage_graph4.png\" alt=\"Aggregate neighbors\" style=\"width: 500px;\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:rgba(192,192,192,0.3); font-size:105%; color:black\">\n",
    "<h4> Step 4:</h4>\n",
    "<p>Update node features.</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\large h_v^k \\leftarrow \\sigma\\left(\\mathbf{W}^k\\cdot\\text{CONCAT}\\left(\\mathbf{h}_v^{k-1},\\mathbf{h}_{\\mathcal{N}(v)}^{k}\\right)\\right)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "update_lin = torch.nn.Linear(\n",
    "            in_channels + out_channels, in_channels, bias=False\n",
    "        )\n",
    "update_act = torch.nn.ReLU()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_embedding = torch.cat([new_x, g.x], dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 6.0695,  3.2117,  2.0000,  1.0000],\n",
       "        [ 6.0695,  4.1926,  5.0000,  6.0000],\n",
       "        [ 6.3324,  4.1926,  3.0000,  7.0000],\n",
       "        [ 6.3324,  0.4609, 12.0000,  0.0000]], grad_fn=<CatBackward>)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_embedding = update_lin(new_embedding)\n",
    "new_embedding = update_act(new_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[3.8781, 0.0000],\n",
       "        [6.2303, 0.3028],\n",
       "        [7.0244, 1.0545],\n",
       "        [1.2063, 0.0000]], grad_fn=<ReluBackward0>)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\"tmp/viz_objects/gsage_graph5.png\" alt=\"Updated Graph\" style=\"width: 500px;\"/></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3><a href=\"https://arxiv.org/abs/1905.05178\"> $\\mathrm{top}_k$ Pooling operator from \"Graph U-Nets\"</a><h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:rgba(192,192,192,0.3); font-size:105%; color:black\">\n",
    "<h4>Motivation:</h4>\n",
    "<b>Traditional Pooling:</b><br>\n",
    "<ul><li>On grid-like\n",
    "data such as images, feature maps are partitioned into non-overlapping rectangles, on which non-linear down-sampling\n",
    "functions like maximum are applied.\n",
    "<li>This can reduce sizes of feature maps and enlarge\n",
    "receptive fields, thereby giving rise to better generalization and performance.</ul>\n",
    "<b>Issues with applying these on Graph Networks:</b><br>\n",
    " <ul>\n",
    "    <li>There is no locality information\n",
    "among nodes in graphs. Thus the partition operation is not\n",
    "applicable on graphs.</li>\n",
    "    <li>The global pooling operation will\n",
    "reduce all nodes to one single node, which restricts the\n",
    "flexibility of networks.</li> \n",
    "    <li>The k-max pooling operation outputs the k-largest units that may come from different nodes\n",
    "in graphs, resulting in inconsistency in the connectivity of\n",
    "selected nodes.</li>\n",
    "</ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\"tmp/viz_objects/topk_1.png\" alt=\"Top k Pooling\" style=\"width: 900px;\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:rgba(192,192,192,0.3); font-size:105%; color:black\">\n",
    "<b>Layer-wise propagation rule:</b><br>\n",
    "$x^{\\ell}$ is the feature matrix with row vectors $x_1^{\\ell},x_2^{\\ell},...,x_N^{\\ell},$ each of which corresponds to a node in the graph.\n",
    "<ol>\n",
    "<li> We first\n",
    "compute the scalar projection of $X^{\\ell}$ on $p^{\\ell}$, resulting in\n",
    "$y = [y_1, y_2, · · · , y_N ]^T$ with each $y_i$ measuring the scalar\n",
    "projection value of each node on the projection vector $p^{\\ell}$.\n",
    "</li>\n",
    "    $$\\large \\mathbf{y}=X^{\\ell}\\mathbf{p}^{\\ell} \\Big/ {\\| \\mathbf{p^{\\ell}} \\|}$$\n",
    "<li>\n",
    "Based on the scalar projection vector $y$, rank(·) operation\n",
    "ranks values and returns the $k$-largest values in $y$. The index selection process preserves the position order information in the original\n",
    "graph.</li>\n",
    "    $$\\large \\text{idx}=\\text{rank}\\left(\\mathbf{y},k\\right)$$\n",
    "<li>With indices idx, we extract the adjacency matrix\n",
    "$A \\in \\mathbb{R}^{k\\text{x}k}$\n",
    "and the feature matrix $\\tilde{X}^{\\ell} \\in \\mathbb{R}^{k\\text{x}C}$ for the new\n",
    "graph.</li>\n",
    "    $$\n",
    "    \\begin{align}\n",
    "    \\large \\tilde{X}^{\\ell}&=X^{\\ell}\\left(\\text{idx},:\\right),\\\\\n",
    "\\large A^{\\ell+1}&=A^{\\ell}\\left(\\text{idx},\\text{idx}\\right)\\\\\n",
    "\\end{align}\n",
    "    $$\n",
    "<li> With selected indices idx, we obtain the gate\n",
    "vector $\\tilde{y} \\in \\mathbb{R}^k$ by applying sigmoid to each element in the\n",
    "extracted scalar projection vector. Using element-wise matrix product of $\\tilde{X}^{\\ell}$\n",
    "and $\\tilde{y}1_{C}^{T}$, information of selected nodes\n",
    "is controlled.</li>\n",
    "    $$\\large \\mathbf{\\tilde{y}}=\\text{sigmoid}\\left(\\mathbf{y}\\left(\\text{idx}\\right)\\right)$$\n",
    "<li>. The $i$th row vector in $X^{\\ell+1}$ is the product of\n",
    "the $i$th row vector in $X^\\ell$\n",
    "and the $i$th scalar value in $\\tilde{y}$.</li>\n",
    "    $$\\large X^{\\ell+1}=\\tilde{X}^{\\ell}\\odot\\left(\\mathbf{\\tilde{y}}\\mathbf{1_{\\it{c}}^{\\it{T}}}\\right)$$\n",
    "</ol>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:rgba(192,192,192,0.3); font-size:105%; color:black\">\n",
    "<b>Need for the Gate Operation</b><br>\n",
    "The gate operation makes the projection vector $\\mathbf{p}$\n",
    "trainable by back-propagation. Without\n",
    "the gate operation, the projection vector $\\mathbf{p}$ produces discrete\n",
    "outputs, which makes it not trainable by back-propagation.\n",
    "    </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:rgba(192,192,192,0.3); font-size:105%; color:black\">\n",
    "<h4> References:</h4>\n",
    "<ol>\n",
    "<li><a href = \"https://arxiv.org/abs/1812.08434\">Graph Neural Networks: A Review of Methods and Applications</a>\n",
    "<li><a href=\"https://arxiv.org/pdf/1905.05178.pdf\">Graph U-Nets</a>\n",
    "<li><a href = \"https://pytorch-geometric.readthedocs.io/en/latest/notes/create_gnn.html\">https://pytorch-geometric.readthedocs.io/en/latest/notes/create_gnn.html</a>\n",
    "<li><a href = \"https://www.youtube.com/watch?v=7JELX6DiUxQ&ab_channel=MachineLearningTV\">https://www.youtube.com/watch?v=7JELX6DiUxQ&ab_channel=MachineLearningTV</a>\n",
    "<li><a href = \"https://towardsdatascience.com/inductive-vs-transductive-learning-e608e786f7d\">https://towardsdatascience.com/inductive-vs-transductive-learning-e608e786f7d</a>\n",
    "</ol>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('gcn': conda)",
   "language": "python",
   "name": "python38564bitgcncondacb855bff8b454c0bbae31f8183fac245"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
